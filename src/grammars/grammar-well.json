{"grammar":{"rules":[{"name":"final$ebnf$1","symbols":[{"token":"(lexer.has(\"ws\") ? {type: \"ws\"} : ws)"}],"postprocess":{"builtin":"id"}},{"name":"final$ebnf$1","symbols":[],"postprocess":{"builtin":"nuller"}},{"name":"final","symbols":["_","prog","_","final$ebnf$1"],"postprocess":" function(d) { return d[1]; } "},{"name":"prog","symbols":["prod"],"postprocess":" function(d) { return [d[0]]; } "},{"name":"prog","symbols":["prod","ws","prog"],"postprocess":" function(d) { return [d[0]].concat(d[2]); } "},{"name":"prod","symbols":["word","_",{"token":"(lexer.has(\"arrow\") ? {type: \"arrow\"} : arrow)"},"_","expression+"],"postprocess":" function(d) { return {name: d[0], rules: d[4]}; } "},{"name":"prod","symbols":["word",{"literal":"["},"_","wordlist","_",{"literal":"]"},"_",{"token":"(lexer.has(\"arrow\") ? {type: \"arrow\"} : arrow)"},"_","expression+"],"postprocess":" function(d) {return {macro: d[0], args: d[3], exprs: d[9]}} "},{"name":"prod","symbols":[{"literal":"@"},"_","js"],"postprocess":" function(d) { return {body: d[2]}; } "},{"name":"prod","symbols":[{"literal":"@"},"word","ws","word"],"postprocess":" function(d) { return {config: d[1], value: d[3]}; } "},{"name":"prod","symbols":[{"literal":"@include"},"_","string"],"postprocess":" function(d) {return {include: d[2].literal, builtin: false}} "},{"name":"prod","symbols":[{"literal":"@builtin"},"_","string"],"postprocess":" function(d) {return {include: d[2].literal, builtin: true }} "},{"name":"expression+","symbols":["completeexpression"]},{"name":"expression+","symbols":["expression+","_",{"literal":"|"},"_","completeexpression"],"postprocess":" function(d) { return d[0].concat([d[4]]); } "},{"name":"expressionlist","symbols":["completeexpression"]},{"name":"expressionlist","symbols":["expressionlist","_",{"literal":","},"_","completeexpression"],"postprocess":" function(d) { return d[0].concat([d[4]]); } "},{"name":"wordlist","symbols":["word"]},{"name":"wordlist","symbols":["wordlist","_",{"literal":","},"_","word"],"postprocess":" function(d) { return d[0].concat([d[4]]); } "},{"name":"completeexpression","symbols":["expr"],"postprocess":" function(d) { return {tokens: d[0]}; } "},{"name":"completeexpression","symbols":["expr","_","js"],"postprocess":" function(d) { return {tokens: d[0], transform: d[2]}; } "},{"name":"expr_member","symbols":["word"],"postprocess":" id "},{"name":"expr_member","symbols":[{"literal":"$"},"word"],"postprocess":" function(d) {return {mixin: d[1]}} "},{"name":"expr_member","symbols":["word",{"literal":"["},"_","expressionlist","_",{"literal":"]"}],"postprocess":" function(d) {return {macrocall: d[0], args: d[3]}} "},{"name":"expr_member$ebnf$1","symbols":[{"literal":"i"}],"postprocess":{"builtin":"id"}},{"name":"expr_member$ebnf$1","symbols":[],"postprocess":{"builtin":"nuller"}},{"name":"expr_member","symbols":["string","expr_member$ebnf$1"],"postprocess":" function(d) { if (d[1]) {return insensitive(d[0]); } else {return d[0]; } } "},{"name":"expr_member","symbols":[{"literal":"%"},"word"],"postprocess":" function(d) {return {token: d[1]}} "},{"name":"expr_member","symbols":["charclass"],"postprocess":" id "},{"name":"expr_member","symbols":[{"literal":"("},"_","expression+","_",{"literal":")"}],"postprocess":" function(d) {return {'subexpression': d[2]} ;} "},{"name":"expr_member","symbols":["expr_member","_","ebnf_modifier"],"postprocess":" function(d) {return {'ebnf': d[0], 'modifier': d[2]}; } "},{"name":"ebnf_modifier","symbols":[{"literal":":+"}],"postprocess":" getValue "},{"name":"ebnf_modifier","symbols":[{"literal":":*"}],"postprocess":" getValue "},{"name":"ebnf_modifier","symbols":[{"literal":":?"}],"postprocess":" getValue "},{"name":"expr","symbols":["expr_member"]},{"name":"expr","symbols":["expr","ws","expr_member"],"postprocess":" function(d){ return d[0].concat([d[2]]); } "},{"name":"word","symbols":[{"token":"(lexer.has(\"word\") ? {type: \"word\"} : word)"}],"postprocess":" getValue "},{"name":"string","symbols":[{"token":"(lexer.has(\"string\") ? {type: \"string\"} : string)"}],"postprocess":" d => ({literal: d[0].value}) "},{"name":"string","symbols":[{"token":"(lexer.has(\"btstring\") ? {type: \"btstring\"} : btstring)"}],"postprocess":" d => ({literal: d[0].value}) "},{"name":"charclass","symbols":[{"token":"(lexer.has(\"charclass\") ? {type: \"charclass\"} : charclass)"}],"postprocess":" getValue "},{"name":"js","symbols":[{"token":"(lexer.has(\"js\") ? {type: \"js\"} : js)"}],"postprocess":" getValue "},{"name":"_$ebnf$1","symbols":["ws"],"postprocess":{"builtin":"id"}},{"name":"_$ebnf$1","symbols":[],"postprocess":{"builtin":"nuller"}},{"name":"_","symbols":["_$ebnf$1"]},{"name":"ws","symbols":[{"token":"(lexer.has(\"ws\") ? {type: \"ws\"} : ws)"}]},{"name":"ws$ebnf$1","symbols":[{"token":"(lexer.has(\"ws\") ? {type: \"ws\"} : ws)"}],"postprocess":{"builtin":"id"}},{"name":"ws$ebnf$1","symbols":[],"postprocess":{"builtin":"nuller"}},{"name":"ws","symbols":["ws$ebnf$1",{"token":"(lexer.has(\"comment\") ? {type: \"comment\"} : comment)"},"_"]}],"body":["\nfunction getValue(d) {\n    return d[0].value\n}\n\nfunction literals(list) {\n    var rules = {}\n    for (var lit of list) {\n        rules[lit] = {match: lit, next: 'main'}\n    }\n    return rules\n}\n\nvar moo = require('moo')\nvar rules = Object.assign({\n    ws: {match: /\\s+/, lineBreaks: true, next: 'main'},\n    comment: /\\#.*/,\n    arrow: {match: /[=-]+\\>/, next: 'main'},\n    js: {\n        match: /\\$\\{(?:.*)\\}/,\n        value: x => x.slice(2, -1),\n        lineBreaks: true,\n    },\n    word: {match: /[\\w\\?\\+]+/, next: 'afterWord'},\n    string: {\n        match: /\"(?:[^\\\\\"\\n]|\\\\[\"\\\\/bfnrt]|\\\\u[a-fA-F0-9]{4})*\"/,\n        value: x => JSON.parse(x),\n        next: 'main',\n    },\n    btstring: {\n        match: /`[^`]*`/,\n        value: x => x.slice(1, -1),\n        next: 'main',\n        lineBreaks: true,\n    },\n}, literals([\n    \",\", \"|\", \"$\", \"%\", \"(\", \")\",\n    \":?\", \":*\", \":+\",\n    \"@include\", \"@builtin\", \"@\",\n    \"]\",\n]))\n\nvar lexer = moo.states({\n    main: Object.assign({}, rules, {\n        charclass: {\n            match: /\\.|\\[(?:\\\\.|[^\\\\\\n])+?\\]/,\n            value: x => new RegExp(x),\n        },\n    }),\n    // Both macro arguments and charclasses are both enclosed in [ ].\n    // We disambiguate based on whether the previous token was a `word`.\n    afterWord: Object.assign({}, rules, {\n        \"[\": {match: \"[\", next: 'main'},\n    }),\n})\n\nfunction insensitive(sl) {\n    var s = sl.literal;\n    var result = [];\n    for (var i=0; i<s.length; i++) {\n        var c = s.charAt(i);\n        if (c.toUpperCase() !== c || c.toLowerCase() !== c) {\n            result.push(new RegExp(\"[\" + c.toLowerCase() + c.toUpperCase() + \"]\"));\n            } else {\n            result.push({literal: c});\n        }\n    }\n    return {subexpression: [{tokens: result, postprocess: function(d) {return d.join(\"\"); }}]};\n}\n\n"],"customTokens":["ws","arrow","word","string","btstring","charclass","js","comment"],"config":{"lexer":"lexer"},"macros":{},"start":"final","version":"unknown"},"exportName":"grammar"}